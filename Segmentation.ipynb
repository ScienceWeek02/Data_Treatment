{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/EEG_Scaled_data.csv\"\n",
        "df_sample = pd.read_csv(file_path, nrows=5)\n",
        "print(\"Colonnes du dataset:\", df_sample.columns)\n",
        "print(df_sample.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQfDB2ECXjyR",
        "outputId": "5cffbebd-67e9-48fd-ce99-885c876fd52a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colonnes du dataset: Index(['Channel_1', 'Channel_2', 'Channel_3', 'Channel_4', 'Channel_5',\n",
            "       'Channel_6', 'Channel_7', 'Channel_8', 'Channel_9', 'Channel_10',\n",
            "       ...\n",
            "       'Channel_36856', 'Channel_36857', 'Channel_36858', 'Channel_36859',\n",
            "       'Channel_36860', 'Channel_36861', 'Channel_36862', 'Channel_36863',\n",
            "       'Channel_36864', 'target'],\n",
            "      dtype='object', length=36865)\n",
            "   Channel_1  Channel_2  Channel_3  Channel_4  Channel_5  Channel_6  \\\n",
            "0      0.647      0.149     -0.213     -0.199     -0.287     -0.187   \n",
            "1     -2.450     -2.788     -2.387     -1.370     -1.032     -1.037   \n",
            "2     -0.026     -0.123     -0.347     -0.348      0.027      0.162   \n",
            "3     -0.067     -0.153     -0.180     -0.210     -0.238     -0.183   \n",
            "4     -0.190     -0.299     -0.333     -0.199      0.182      0.261   \n",
            "\n",
            "   Channel_7  Channel_8  Channel_9  Channel_10  ...  Channel_36856  \\\n",
            "0      0.320      0.445      0.482       0.348  ...          0.076   \n",
            "1     -1.253     -1.702     -2.116      -2.019  ...          0.154   \n",
            "2      0.166     -0.045     -0.083      -0.037  ...          0.086   \n",
            "3     -0.147     -0.238     -0.305      -0.187  ...         -0.101   \n",
            "4      0.262     -0.075     -0.403      -0.232  ...          0.621   \n",
            "\n",
            "   Channel_36857  Channel_36858  Channel_36859  Channel_36860  Channel_36861  \\\n",
            "0          0.283          0.365         -0.013         -0.029          0.223   \n",
            "1         -0.023         -0.085          0.178          0.118         -0.030   \n",
            "2          0.262          0.319          0.028          0.144          0.255   \n",
            "3         -0.247         -0.271         -0.216         -0.144         -0.066   \n",
            "4          0.625          0.262          0.127          0.301          0.287   \n",
            "\n",
            "   Channel_36862  Channel_36863  Channel_36864  target  \n",
            "0          0.221          0.175          0.347       0  \n",
            "1          0.048          0.113          0.085       0  \n",
            "2          0.148          0.082          0.133       0  \n",
            "3          0.048         -0.127         -0.296       0  \n",
            "4          0.148          0.191          0.106       0  \n",
            "\n",
            "[5 rows x 36865 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ejd4ohVGuwU"
      },
      "outputs": [],
      "source": [
        "chunk_size = 1000\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Paramètres\n",
        "file_path = \"/content/EEG_Scaled_data.csv\"  # Chemin sur Colab\n",
        "chunk_size = 1000  # Lire petit à petit (ajuster si besoin)\n",
        "window_size = 256  # Taille de la fenêtre (1 seconde si 256 Hz)\n",
        "step_size = 256    # Pas de la fenêtre (peut être < window_size pour du overlapping)\n",
        "target_col = \"target\""
      ],
      "metadata": {
        "id": "UWpsV6LJfJfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def segment_chunk(chunk, window_size=256, step_size=256):\n",
        "    X_segments = []\n",
        "    y_segments = []\n",
        "\n",
        "    data = chunk.drop(columns=[target_col]).values\n",
        "    targets = chunk[target_col].values\n",
        "\n",
        "    for i in range(0, len(chunk) - window_size + 1, step_size):\n",
        "        segment = data[i:i+window_size]\n",
        "        label_segment = targets[i:i+window_size]\n",
        "\n",
        "        # On donne le label 1 à la fenêtre si au moins un point est une crise\n",
        "        label = 1 if np.any(label_segment == 1) else 0\n",
        "\n",
        "        X_segments.append(segment)\n",
        "        y_segments.append(label)\n",
        "\n",
        "    return X_segments, y_segments\n"
      ],
      "metadata": {
        "id": "P6wzGYNHffkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_all, y_all = [], []\n",
        "\n",
        "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
        "    X_seg, y_seg = segment_chunk(chunk, window_size, step_size)\n",
        "    X_all.extend(X_seg)\n",
        "    y_all.extend(y_seg)\n"
      ],
      "metadata": {
        "id": "Iwcs7Bs3fimM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Nombre total de segments générés:\", len(X_all))\n",
        "print(\"Nombre de segments de crise:\", sum(y_all))\n",
        "print(\"Nombre de segments sans crise:\", len(y_all) - sum(y_all))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xEOzuu6g4qP",
        "outputId": "193466c7-8115-4ca0-eb4d-8c3959227d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total de segments générés: 33\n",
            "Nombre de segments de crise: 25\n",
            "Nombre de segments sans crise: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier combien de lignes totales sont associées à une crise\n",
        "count_0, count_1 = 0, 0\n",
        "for chunk in pd.read_csv(file_path, usecols=[target_col], chunksize=50000):\n",
        "    count_0 += (chunk[target_col] == 0).sum()\n",
        "    count_1 += (chunk[target_col] == 1).sum()\n",
        "\n",
        "print(f\"Lignes sans crise: {count_0}, Lignes avec crise: {count_1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kn4nM6_9h_ya",
        "outputId": "bf470e67-1903-4c4d-b837-18693c4b48a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lignes sans crise: 9799, Lignes avec crise: 1434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Paramètres\n",
        "file_path = \"/content/EEG_Scaled_data.csv\"  # adapte si nécessaire\n",
        "target_col = \"target\"\n",
        "window_size = 256\n",
        "step_size = 64\n",
        "output_dir = \"/content/segments_npz\"\n",
        "\n",
        "# Créer le dossier de sortie s'il n'existe pas\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Variables pour le suivi\n",
        "segment_count = 0\n",
        "crisis_count = 0\n",
        "non_crisis_count = 0\n",
        "buffer = pd.DataFrame()\n",
        "\n",
        "# Lire le fichier par chunks\n",
        "for chunk in pd.read_csv(file_path, chunksize=1000):\n",
        "    buffer = pd.concat([buffer, chunk], ignore_index=True)\n",
        "\n",
        "    # Tant qu'on a assez de lignes pour une fenêtre\n",
        "    while len(buffer) >= window_size:\n",
        "        segment = buffer.iloc[:window_size]\n",
        "        label = 1 if segment[target_col].sum() > 0 else 0\n",
        "\n",
        "        # Sauvegarde du segment\n",
        "        filename = f\"segment_{segment_count:05d}.npz\"\n",
        "        np.savez_compressed(os.path.join(output_dir, filename),\n",
        "                            data=segment.drop(columns=[target_col]).to_numpy(),\n",
        "                            label=label)\n",
        "\n",
        "        # Compter\n",
        "        segment_count += 1\n",
        "        if label == 1:\n",
        "            crisis_count += 1\n",
        "        else:\n",
        "            non_crisis_count += 1\n",
        "\n",
        "        # Supprimer les lignes utilisées en fonction du step\n",
        "        buffer = buffer.iloc[step_size:].reset_index(drop=True)\n",
        "\n",
        "print(f\"Segments générés : {segment_count}\")\n",
        "print(f\"  → Avec crise : {crisis_count}\")\n",
        "print(f\"  → Sans crise : {non_crisis_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6-xjD8Q7QoO",
        "outputId": "04348e9d-4e92-43b1-d249-308555b7c7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segments générés : 172\n",
            "  → Avec crise : 139\n",
            "  → Sans crise : 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from glob import glob\n",
        "\n",
        "segment_files = glob(\"/content/segments_npz/*.npz\")\n",
        "for file in segment_files[:5]:  # afficher les 5 premiers\n",
        "    data = np.load(file)\n",
        "    print(\"Shape:\", data['data'].shape, \"Label:\", data['label'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frqlCFGDB-hl",
        "outputId": "518cd575-e01e-4532-9fce-64a56d80ca15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (256, 36864) Label: 1\n",
            "Shape: (256, 36864) Label: 0\n",
            "Shape: (256, 36864) Label: 0\n",
            "Shape: (256, 36864) Label: 1\n",
            "Shape: (256, 36864) Label: 0\n"
          ]
        }
      ]
    }
  ]
}